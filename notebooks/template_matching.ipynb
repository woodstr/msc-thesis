{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e876f5cd",
   "metadata": {},
   "source": [
    "# Notes for Possible Improvements\n",
    "- Grid estimation could be improved by linear regression after assigning each point to appropriate gridline.\n",
    "    - Estimation using x,y coords of point centers for each horizontal and vertical grid. This would improve the gridline intersection accuracy on deformations and orientation errors.\n",
    "    - Would increase complexity with e.g. 256 regressions with 16x16 DMC\n",
    "    - Possible efficient solution could be to only have 2 or 4 regressions on DMC alignment pattern, and copying their params accross other gridlines.\n",
    "- Simple guaranteed error correction before final decoding process\n",
    "    - Force L and timing to be black as they are consistent\n",
    "- Implementation of decoding instead of using pylibdmtx\n",
    "    - Have not done yet due to complexity of it (even though it is deterministic algorithms)\n",
    "    - Could possibly \"steal\" relevant parts from pylibdmtx or libdmtx and rewrite for this purpose\n",
    "- Rewrites for squeezing out performance is possible\n",
    "    - Avoiding later matrix inversion by assigning 1s and 0s in reverse\n",
    "    - Avoiding multiple sorting by ensuring methods do not reorder points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159a45fd",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b663d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from pylibdmtx.pylibdmtx import decode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efef5fd4",
   "metadata": {},
   "source": [
    "## Yucheng Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707d6f2a",
   "metadata": {},
   "source": [
    "## Yucheng Funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f81b439",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_scale_retinex(image, sigma=30):\n",
    "    \"\"\"\n",
    "    Does single scale retinex on the input image.\n",
    "\n",
    "    Args:\n",
    "        image: Input image (numpy array)\n",
    "        sigma: Gaussian kernel size (default is 30)\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of reflectance and illumination images\n",
    "    \"\"\"\n",
    "    image = image.astype(np.float32) + 1.0\n",
    "    illumination = cv2.GaussianBlur(image, (0, 0), sigma)\n",
    "    illumination += 1.0\n",
    "    reflectance = np.log(image) - np.log(illumination)\n",
    "    reflectance_display = cv2.normalize(reflectance, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    reflectance_display = reflectance_display.astype(np.uint8)\n",
    "    illumination_display = cv2.normalize(illumination, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "    return reflectance_display, illumination_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b9251e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression_fast(boxes, scores, overlap_thresh=0.3):\n",
    "    \"\"\"\n",
    "    Perform non-maximum suppression on the bounding boxes.\n",
    "\n",
    "    Args:\n",
    "        boxes: List of bounding boxes (x, y, width, height)\n",
    "        scores: List of scores for each bounding box\n",
    "        overlap_thresh: Overlap threshold for suppression (default is 0.3)\n",
    "    \n",
    "    Returns:\n",
    "        List of bounding boxes after non-maximum suppression\n",
    "    \"\"\"\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "    boxes = np.array(boxes)\n",
    "    scores = np.array(scores)\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 0] + boxes[:, 2]\n",
    "    y2 = boxes[:, 1] + boxes[:, 3]\n",
    "    areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = scores.argsort()[::-1]\n",
    "    keep = []\n",
    "    while len(idxs) > 0:\n",
    "        i = idxs[0]\n",
    "        keep.append(i)\n",
    "        xx1 = np.maximum(x1[i], x1[idxs[1:]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[1:]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[1:]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[1:]])\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "        inter = w * h\n",
    "        overlap = inter / (areas[i] + areas[idxs[1:]] - inter)\n",
    "        idxs = idxs[1:][overlap < overlap_thresh]\n",
    "    return boxes[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef549aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dominant_dot_template(image, min_area=20, max_area=300, patch_size=(24, 24), offset=5, size_tol=0.5):\n",
    "    \"\"\"\n",
    "    Extracts the dominant dot template from the image.\n",
    "    The function applies a series of image processing techniques to identify and extract the dot template.\n",
    "\n",
    "    Args:\n",
    "        image: Input image (numpy array)\n",
    "        min_area: Minimum area of the dot to be considered (default is 20)\n",
    "        max_area: Maximum area of the dot to be considered (default is 300)\n",
    "        patch_size: Size of the patch to be extracted (default is (24, 24))\n",
    "        offset: Offset for bounding box around the detected dot (default is 5)\n",
    "        size_tol: Tolerance for size consistency (default is 0.5)\n",
    "\n",
    "    Returns:\n",
    "        Tuple of the extracted patch and contours of the detected dots.\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: If no valid dot candidates are found or if no size-consistent patches are found.\n",
    "    \"\"\"\n",
    "    image_clean = cv2.bilateralFilter(image, d=15, sigmaColor=50, sigmaSpace=5)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    image_clean = clahe.apply(image_clean)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (16, 16))\n",
    "    tophat = cv2.morphologyEx(image_clean, cv2.MORPH_BLACKHAT, kernel)\n",
    "\n",
    "    _, binary_top = cv2.threshold(tophat, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    contours, _ = cv2.findContours(binary_top, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    candidates = []\n",
    "    sizes = []\n",
    "    img_w, img_h = image.shape\n",
    "\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if min_area < area < max_area:\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            crop_x_start = x - offset\n",
    "            crop_x_end = x + w + offset\n",
    "            crop_y_start = y - offset\n",
    "            crop_y_end = y + h + offset\n",
    "\n",
    "            if crop_x_start < 0 or crop_x_end >= img_w or crop_y_start < 0 or crop_y_end >= img_h:\n",
    "                continue\n",
    "\n",
    "            patch = image[crop_y_start:crop_y_end, crop_x_start:crop_x_end]\n",
    "            candidates.append((patch, h, w))\n",
    "            sizes.append((h, w))\n",
    "\n",
    "    if not candidates:\n",
    "        raise ValueError(\"No valid dot candidates found.\")\n",
    "\n",
    "    # Compute median size\n",
    "    heights = [s[0] for s in sizes]\n",
    "    widths = [s[1] for s in sizes]\n",
    "    median_area = np.median(heights) * np.median(widths)\n",
    "\n",
    "    # Keep only patches with similar size\n",
    "    patches_filtered = []\n",
    "    resized_for_matching = []\n",
    "    for (patch, h, w) in candidates:\n",
    "        # print(abs(h * w - median_area))\n",
    "        if abs(h * w - median_area) / median_area < size_tol:\n",
    "            patches_filtered.append(patch)\n",
    "            resized_for_matching.append(cv2.resize(patch, patch_size))\n",
    "\n",
    "    if not patches_filtered:\n",
    "        raise ValueError(\"No size-consistent patches found.\")\n",
    "\n",
    "    # Find patch closest to the median template\n",
    "    stack = np.stack(resized_for_matching, axis=0).astype(np.float32)\n",
    "    median_template = np.median(stack, axis=0)\n",
    "    diffs = [np.linalg.norm(p.astype(np.float32) - median_template) for p in resized_for_matching]\n",
    "    best_idx = np.argmin(diffs)\n",
    "\n",
    "    return patches_filtered[best_idx], contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779517b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contours_from_patch(patch):\n",
    "    \"\"\"\n",
    "    Extracts contours from supplied patch image.\n",
    "    \"\"\"\n",
    "    _, binary_patch = cv2.threshold(patch, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    contours, _ = cv2.findContours(binary_patch, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f710876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(image, size=(300, 300)):\n",
    "    \"\"\"\n",
    "    Displays the numpy image using PIL and notebook display functionality.\n",
    "\n",
    "    Args:\n",
    "        image: Input image (numpy array)\n",
    "        size: Size to which the image should be resized (default is (300, 300))\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, size)\n",
    "    pil_image = Image.fromarray(image)\n",
    "    display(pil_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a90c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_yucheng_methods(nms_boxes, reflectance, dot_contours, img, illumination, dot_template):\n",
    "    \"\"\"\n",
    "    Displays the results of Yuchengs methods for dot detection and template matching.\n",
    "\n",
    "    Args:\n",
    "        nms_boxes: List of bounding boxes after non-maximum suppression\n",
    "        reflectance: Reflectance map (numpy array)\n",
    "        dot_contours: Contours of the detected dots\n",
    "        img: Original image (numpy array)\n",
    "        illumination: Estimated illumination (numpy array)\n",
    "        dot_template: Dot template (numpy array)\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # === Draw matching result ===\n",
    "    output = cv2.cvtColor(reflectance, cv2.COLOR_GRAY2BGR)\n",
    "    for (x, y, w, h) in nms_boxes:\n",
    "        cv2.rectangle(output, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # === Draw contours over reflectance ===\n",
    "    contour_vis = cv2.cvtColor(reflectance, cv2.COLOR_GRAY2BGR)\n",
    "    cv2.drawContours(contour_vis, dot_contours, -1, (0, 0, 255), 1)\n",
    "\n",
    "    # === Show results ===\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(10, 6))\n",
    "    axs[0, 0].imshow(img, cmap='gray')\n",
    "    axs[0, 0].set_title(\"Original Image\")\n",
    "    axs[0, 0].axis(\"off\")\n",
    "\n",
    "    axs[0, 1].imshow(illumination, cmap='gray')\n",
    "    axs[0, 1].set_title(\"Estimated Illumination\")\n",
    "    axs[0, 1].axis(\"off\")\n",
    "\n",
    "    axs[0, 2].imshow(reflectance, cmap='gray')\n",
    "    axs[0, 2].set_title(\"Reflectance Map (SSR)\")\n",
    "    axs[0, 2].axis(\"off\")\n",
    "\n",
    "    axs[1, 0].imshow(cv2.cvtColor(contour_vis, cv2.COLOR_BGR2RGB))\n",
    "    axs[1, 0].set_title(\"Dot Contours\")\n",
    "    axs[1, 0].axis(\"off\")\n",
    "\n",
    "    axs[1, 1].imshow(dot_template, cmap='gray')\n",
    "    axs[1, 1].set_title(\"Dot template (median of patches)\")\n",
    "    axs[1, 1].axis(\"off\")\n",
    "\n",
    "    axs[1, 2].imshow(cv2.cvtColor(output, cv2.COLOR_BGR2RGB))\n",
    "    axs[1, 2].set_title(\"Template matching\")\n",
    "    axs[1, 2].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb86f39",
   "metadata": {},
   "source": [
    "## Yucheng Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be9f7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load image (grayscale) ===\n",
    "img_to_test = \"../data/delete.jpg\"\n",
    "template_to_test = \"../data/delete_template.jpg\"\n",
    "img = cv2.imread(img_to_test, cv2.IMREAD_GRAYSCALE)\n",
    "img = cv2.resize(img, (320, 320))\n",
    "dot_template = cv2.imread(template_to_test, cv2.IMREAD_GRAYSCALE)\n",
    "dot_template = cv2.resize(dot_template, (19, 19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cf6b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Apply Retinex ===\n",
    "reflectance, illumination = single_scale_retinex(img, sigma=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec23de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_contours = contours_from_patch(dot_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdfe8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # === Extract dominant template and contours ===\n",
    "# # REPLACE WITH YOUR ACTUAL TEMPLATE\n",
    "# dot_template, dot_contours = extract_dominant_dot_template(reflectance,\n",
    "#                                                            min_area=20,\n",
    "#                                                            max_area=300,\n",
    "#                                                            patch_size=(24, 24),\n",
    "#                                                            offset=5,\n",
    "#                                                            size_tol=0.5)\n",
    "\n",
    "# display_image(dot_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2930ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Template matching ===\n",
    "result = cv2.matchTemplate(reflectance, dot_template, cv2.TM_CCOEFF_NORMED)\n",
    "threshold = 0.7\n",
    "locations = zip(*np.where(result >= threshold)[::-1])\n",
    "scores = result[result >= threshold].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5835ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Bounding boxes (x, y, w, h) for each match ===\n",
    "h, w = dot_template.shape\n",
    "boxes = [(int(x), int(y), w, h) for (x, y) in locations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44f98d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Apply NMS ===\n",
    "nms_boxes = non_max_suppression_fast(boxes, scores, overlap_thresh=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f9db89",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_yucheng_methods(nms_boxes, reflectance, dot_contours, img, illumination, dot_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2725a5",
   "metadata": {},
   "source": [
    "# Decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcffc71",
   "metadata": {},
   "source": [
    "## Decoding Funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1759f89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_estimation(nms_boxes, dmc_size=16):\n",
    "    \"\"\"\n",
    "    Estimate DMC grid from the detected bounding boxes.\n",
    "    Using KMeans clustering on the x and y coordinates of the boxes to find the grid lines.\n",
    "    The function assumes that the boxes are aligned in a grid pattern and correct orientation was previously applied.\n",
    "\n",
    "    Args:\n",
    "        nms_boxes: List of bounding boxes (x, y, width, height)\n",
    "        dmc_size: Size of the DMC (default is 16 for 16x16 DMC)\n",
    "    \n",
    "    Returns:\n",
    "        List of estimated grid lines (x_list, y_list)\n",
    "    \"\"\"\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "\n",
    "    for box in nms_boxes:\n",
    "        x, y, w, h = box\n",
    "        x_list.append(x + w // 2)\n",
    "        y_list.append(y + h // 2)\n",
    "    \n",
    "    x_list = np.array(x_list)\n",
    "    y_list = np.array(y_list)\n",
    "\n",
    "    kmeans_x = KMeans(n_clusters=dmc_size, random_state=0).fit(x_list.reshape(-1, 1))\n",
    "    kmeans_y = KMeans(n_clusters=dmc_size, random_state=0).fit(y_list.reshape(-1, 1))\n",
    "\n",
    "    x_centers = kmeans_x.cluster_centers_.flatten()\n",
    "    y_centers = kmeans_y.cluster_centers_.flatten()\n",
    "\n",
    "    x_centers = np.sort(x_centers)\n",
    "    y_centers = np.sort(y_centers)\n",
    "\n",
    "    return x_centers.astype(int), y_centers.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535163f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_grid(image, x_centers, y_centers):\n",
    "    \"\"\"\n",
    "    Display the grid on the image.\n",
    "\n",
    "    Args:\n",
    "        image: Input image (numpy array)\n",
    "        x_centers: List of x coordinates for grid lines\n",
    "        y_centers: List of y coordinates for grid lines\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    for x in x_centers:\n",
    "        cv2.line(image, (x, 0), (x, image.shape[0]), (255, 0, 0), 1)\n",
    "    for y in y_centers:\n",
    "        cv2.line(image, (0, y), (image.shape[1], y), (255, 0, 0), 1)\n",
    "\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(\"Grid Estimation\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b89691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grid_intersections(x_centers, y_centers):\n",
    "    \"\"\"\n",
    "    Get the grid intersections from the x and y coordinates.\n",
    "\n",
    "    Args:\n",
    "        x_centers: List of x coordinates for grid lines\n",
    "        y_centers: List of y coordinates for grid lines\n",
    "    \n",
    "    Returns:\n",
    "        List of grid intersections (x, y)\n",
    "    \"\"\"\n",
    "    intersections = []\n",
    "    for x in x_centers:\n",
    "        for y in y_centers:\n",
    "            intersections.append((x, y))\n",
    "    return intersections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0568c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_grid_intersections(image, intersections):\n",
    "    \"\"\"\n",
    "    Display the grid intersections on the image.\n",
    "\n",
    "    Args:\n",
    "        image: Input image (numpy array)\n",
    "        intersections: List of grid intersections (x, y)\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    for (x, y) in intersections:\n",
    "        cv2.circle(image, (x, y), 3, (0, 255, 0), -1)\n",
    "\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(\"Grid Intersections\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32920189",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_intersection(x, y, intersections):\n",
    "    \"\"\"\n",
    "    Find the closest grid intersection to the given coordinates.\n",
    "\n",
    "    Args:\n",
    "        x: x coordinate\n",
    "        y: y coordinate\n",
    "        intersections: List of grid intersections (x, y)\n",
    "    \n",
    "    Returns:\n",
    "        Closest intersection (x, y)\n",
    "    \"\"\"\n",
    "    closest = None\n",
    "    min_dist = float('inf')\n",
    "    for (ix, iy) in intersections:\n",
    "        dist = np.sqrt((x - ix) ** 2 + (y - iy) ** 2)\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            closest = (ix, iy)\n",
    "    return closest\n",
    "\n",
    "def find_all_closest_intersections(coords, intersections):\n",
    "    \"\"\"\n",
    "    Find the closest grid intersections for a list of coordinates.\n",
    "\n",
    "    Args:\n",
    "        coords: List of coordinates (x, y)\n",
    "        intersections: List of grid intersections (x, y)\n",
    "    \n",
    "    Returns:\n",
    "        List of closest intersections (x, y)\n",
    "    \"\"\"\n",
    "    closest_intersections = []\n",
    "    for (x, y) in coords:\n",
    "        x_center = x + w // 2\n",
    "        y_center = y + h // 2\n",
    "        closest = find_closest_intersection(x_center, y_center, intersections)\n",
    "        closest_intersections.append(closest)\n",
    "    return closest_intersections\n",
    "\n",
    "def display_closest_intersections(image, nms_boxes, closest_intersections):\n",
    "    \"\"\"\n",
    "    Displays bounding boxes and their closest intersections.\n",
    "    \"\"\"\n",
    "    output = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "    for (x, y, w, h), (ix, iy) in zip(nms_boxes, closest_intersections):\n",
    "        cv2.rectangle(output, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.circle(output, (ix, iy), 3, (255, 0, 0), -1)\n",
    "\n",
    "    plt.imshow(output)\n",
    "    plt.title(\"Closest Intersections\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f3488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix_map(intersections):\n",
    "    \"\"\"\n",
    "    Builds a mapping of intersections to their underlying matrix indices.\n",
    "\n",
    "    Args:\n",
    "        intersections: List of grid intersections (x, y)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary mapping (x, y) to matrix index\n",
    "        size of the matrix\n",
    "    \"\"\"\n",
    "    matrix_map = {}\n",
    "    last_y = None\n",
    "    row = -1\n",
    "    col = -1\n",
    "\n",
    "    # Sort intersections by y (ascending) and x (ascending) so that we loop from top to bottom and left to right\n",
    "    intersections = sorted(intersections, key=lambda p: (p[1], p[0]))\n",
    "\n",
    "    for x, y in intersections:\n",
    "        col += 1\n",
    "        if y != last_y:\n",
    "            row += 1\n",
    "            last_y = y\n",
    "            col = 0\n",
    "        matrix_map[(x, y)] = (row, col)\n",
    "\n",
    "    return matrix_map, row+1\n",
    "\n",
    "def build_matrix(matrix_map, closest_intersections, dmc_size):\n",
    "    \"\"\"\n",
    "    Build a matrix from the grid intersections and their closest intersections.\n",
    "\n",
    "    Args:\n",
    "        matrix_map: Dictionary mapping (x, y) to matrix index\n",
    "        closest_intersections: List of closest intersections (x, y)\n",
    "    \n",
    "    Returns:\n",
    "        Numpy array representing the matrix with 1s at the closest intersections\n",
    "        and 0s elsewhere.\n",
    "    \"\"\"\n",
    "    matrix = np.zeros((dmc_size, dmc_size), dtype=np.uint8)\n",
    "\n",
    "    for (x, y) in closest_intersections:\n",
    "        x_index, y_index = matrix_map[(x, y)]\n",
    "        matrix[x_index, y_index] = 1\n",
    "    return matrix\n",
    "\n",
    "def display_DMC(matrix):\n",
    "    \"\"\"\n",
    "    Display the DMC matrix like normal DMC.\n",
    "\n",
    "    Args:\n",
    "        matrix: Numpy array representing the DMC matrix\n",
    "    \"\"\"\n",
    "    # Invert the matrix for display\n",
    "    matrix = np.invert(matrix)\n",
    "    plt.imshow(matrix, cmap='gray', interpolation='nearest')\n",
    "    plt.title(\"DMC Matrix\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea99af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_DMC(matrix):\n",
    "    \"\"\"\n",
    "    Decodes the DMC matrix using pylibdmtx.\n",
    "\n",
    "    Args:\n",
    "        matrix: Numpy array representing the DMC matrix\n",
    "    \n",
    "    Returns:\n",
    "        \n",
    "    \"\"\"\n",
    "    # Converting binary matrix to uint8 image\n",
    "    image = np.zeros((matrix.shape[0], matrix.shape[1]), dtype=np.uint8)\n",
    "    image[matrix == 1] = 255\n",
    "    image = Image.fromarray(image, 'L')\n",
    "\n",
    "    # Inverting the image for decoding\n",
    "    image = Image.eval(image, lambda x: 255 - x)\n",
    "\n",
    "    # Padding the image by 2 pixels to add margin larger than a DMC module (https://www.keyence.eu/ss/products/auto_id/codereader/basic_2d/datamatrix.jsp)\n",
    "    image = np.pad(np.array(image), ((2, 2), (2, 2)), mode='constant', constant_values=255)\n",
    "    image = Image.fromarray(image, 'L')\n",
    "\n",
    "    # Resizing to larger image for better decoding\n",
    "    image = image.resize((image.size[0] * 10, image.size[1] * 10), Image.NEAREST)\n",
    "\n",
    "    # Decode using pylibdmtx\n",
    "    decoded = decode(image)\n",
    "    if decoded:\n",
    "        return decoded[0].data.decode('utf-8')\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a467774b",
   "metadata": {},
   "source": [
    "## Decoding Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664f56f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Estimating Grid ===\n",
    "x_centers, y_centers = grid_estimation(nms_boxes)\n",
    "display_grid(reflectance.copy(), x_centers, y_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96df67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Get grid intersections ===\n",
    "intersections = get_grid_intersections(x_centers, y_centers)\n",
    "display_grid_intersections(reflectance.copy(), intersections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc4c610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Find closest intersection ===\n",
    "closest_intersections = find_all_closest_intersections(nms_boxes[:, :2], intersections)\n",
    "display_closest_intersections(reflectance.copy(), nms_boxes, closest_intersections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aa435d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Convert to original DMC ===\n",
    "matrix_map, dmc_size = get_matrix_map(intersections)\n",
    "matrix = build_matrix(matrix_map, closest_intersections, dmc_size)\n",
    "display_DMC(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e63b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Manually fixing error in example ===\n",
    "matrix[15, 8] = 1\n",
    "display_DMC(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14498608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Decoding DMC ===\n",
    "decoded_data = decode_DMC(matrix)\n",
    "print(decoded_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcff2487",
   "metadata": {},
   "source": [
    "# Full Decoding Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55e21fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_pipeline(image_path, template_path, debug=False):\n",
    "    \"\"\"\n",
    "    Performs the entire decoding pipeline on the input image and template.\n",
    "\n",
    "    Args:\n",
    "        image_path: Path to the input image\n",
    "        template_path: Path to the template image\n",
    "    \n",
    "    Returns:\n",
    "        Decoded data from the DMC matrix or None if decoding fails.\n",
    "    \"\"\"\n",
    "    # === Load image (grayscale) ===\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (320, 320))\n",
    "    dot_template = cv2.imread(template_path, cv2.IMREAD_GRAYSCALE)\n",
    "    dot_template = cv2.resize(dot_template, (19, 19))\n",
    "\n",
    "    # === Apply Retinex ===\n",
    "    reflectance, illumination = single_scale_retinex(img, sigma=64)\n",
    "\n",
    "    # === Extract dot contours ===\n",
    "    dot_contours = contours_from_patch(dot_template)\n",
    "\n",
    "    # === Template matching ===\n",
    "    result = cv2.matchTemplate(reflectance, dot_template, cv2.TM_CCOEFF_NORMED)\n",
    "    threshold = 0.7\n",
    "    locations = zip(*np.where(result >= threshold)[::-1])\n",
    "    scores = result[result >= threshold].flatten()\n",
    "\n",
    "    # === Bounding boxes (x, y, w, h) for each match ===\n",
    "    h, w = dot_template.shape\n",
    "    boxes = [(int(x), int(y), w, h) for (x, y) in locations]\n",
    "\n",
    "    # === Apply NMS ===\n",
    "    nms_boxes = non_max_suppression_fast(boxes, scores, overlap_thresh=0.3)\n",
    "\n",
    "    if debug:\n",
    "        display_yucheng_methods(nms_boxes, reflectance, dot_contours, img, illumination, dot_template)\n",
    "\n",
    "    # === Estimating Grid ===\n",
    "    x_centers, y_centers = grid_estimation(nms_boxes)\n",
    "    if debug:\n",
    "        display_grid(reflectance.copy(), x_centers, y_centers)\n",
    "\n",
    "    # === Get grid intersections ===\n",
    "    intersections = get_grid_intersections(x_centers, y_centers)\n",
    "    if debug:\n",
    "        display_grid_intersections(reflectance.copy(), intersections)\n",
    "\n",
    "    # === Find closest intersection ===\n",
    "    closest_intersections = find_all_closest_intersections(nms_boxes[:, :2], intersections)\n",
    "    if debug:\n",
    "        display_closest_intersections(reflectance.copy(), nms_boxes, closest_intersections)\n",
    "\n",
    "    # === Convert to original DMC ===\n",
    "    matrix_map, dmc_size = get_matrix_map(intersections)\n",
    "    matrix = build_matrix(matrix_map, closest_intersections, dmc_size)\n",
    "    if debug:\n",
    "        display_DMC(matrix)\n",
    "\n",
    "    # === Manually fixing error in example delete this in future ===\n",
    "    matrix[15, 8] = 1\n",
    "\n",
    "    # === Decoding DMC ===\n",
    "    decoded_data = decode_DMC(matrix)\n",
    "\n",
    "    return decoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba11c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_to_test = \"../data/delete.jpg\"\n",
    "template_to_test = \"../data/delete_template.jpg\"\n",
    "decode_pipeline(img_to_test, template_to_test, debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
