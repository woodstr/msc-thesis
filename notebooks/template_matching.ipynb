{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e876f5cd",
   "metadata": {},
   "source": [
    "# Notes for Possible Improvements\n",
    "- Implementation of decoding instead of using pylibdmtx\n",
    "    - Have not done yet due to complexity of it (even though it is deterministic algorithms)\n",
    "    - Could possibly \"steal\" relevant parts from pylibdmtx or libdmtx and rewrite for this purpose\n",
    "- Rewrites for squeezing out performance is possible\n",
    "    - Avoiding later matrix inversion by assigning 1s and 0s in reverse\n",
    "    - Avoiding multiple sorting by ensuring methods do not reorder points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159a45fd",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b663d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.path import Path\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.spatial import ConvexHull\n",
    "from collections import Counter\n",
    "\n",
    "from pylibdmtx.pylibdmtx import decode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875dd122",
   "metadata": {},
   "source": [
    "## Simple Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31f6f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple helper functions\n",
    "def get_mode(lst):\n",
    "    \"\"\"Get the mode of a list.\"\"\"\n",
    "    return Counter(lst).most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6d176e",
   "metadata": {},
   "source": [
    "# Template Matching (thx Yucheng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f81b439",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_scale_retinex(image, sigma=30):\n",
    "    \"\"\"\n",
    "    Does single scale retinex on the input image.\n",
    "\n",
    "    Args:\n",
    "        image: Input image (numpy array)\n",
    "        sigma: Gaussian kernel size (default is 30)\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of reflectance and illumination images\n",
    "    \"\"\"\n",
    "    image = image.astype(np.float32) + 1.0\n",
    "    illumination = cv2.GaussianBlur(image, (0, 0), sigma)\n",
    "    illumination += 1.0\n",
    "    reflectance = np.log(image) - np.log(illumination)\n",
    "    reflectance_display = cv2.normalize(reflectance, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    reflectance_display = reflectance_display.astype(np.uint8)\n",
    "    illumination_display = cv2.normalize(illumination, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "    return reflectance_display, illumination_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b9251e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression_fast(boxes, scores, overlap_thresh=0.3):\n",
    "    \"\"\"\n",
    "    Perform non-maximum suppression on the bounding boxes.\n",
    "\n",
    "    Args:\n",
    "        boxes: List of bounding boxes (x, y, width, height)\n",
    "        scores: List of scores for each bounding box\n",
    "        overlap_thresh: Overlap threshold for suppression (default is 0.3)\n",
    "    \n",
    "    Returns:\n",
    "        List of bounding boxes after non-maximum suppression\n",
    "    \"\"\"\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "    boxes = np.array(boxes)\n",
    "    scores = np.array(scores)\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 0] + boxes[:, 2]\n",
    "    y2 = boxes[:, 1] + boxes[:, 3]\n",
    "    areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = scores.argsort()[::-1]\n",
    "    keep = []\n",
    "    while len(idxs) > 0:\n",
    "        i = idxs[0]\n",
    "        keep.append(i)\n",
    "        xx1 = np.maximum(x1[i], x1[idxs[1:]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[1:]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[1:]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[1:]])\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "        inter = w * h\n",
    "        overlap = inter / (areas[i] + areas[idxs[1:]] - inter)\n",
    "        idxs = idxs[1:][overlap < overlap_thresh]\n",
    "    return boxes[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef549aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dominant_dot_template(image, min_area=20, max_area=300, patch_size=(24, 24), offset=5, size_tol=0.5):\n",
    "    \"\"\"\n",
    "    Extracts the dominant dot template from the image.\n",
    "    The function applies a series of image processing techniques to identify and extract the dot template.\n",
    "\n",
    "    Args:\n",
    "        image: Input image (numpy array)\n",
    "        min_area: Minimum area of the dot to be considered (default is 20)\n",
    "        max_area: Maximum area of the dot to be considered (default is 300)\n",
    "        patch_size: Size of the patch to be extracted (default is (24, 24))\n",
    "        offset: Offset for bounding box around the detected dot (default is 5)\n",
    "        size_tol: Tolerance for size consistency (default is 0.5)\n",
    "\n",
    "    Returns:\n",
    "        Tuple of the extracted patch and contours of the detected dots.\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: If no valid dot candidates are found or if no size-consistent patches are found.\n",
    "    \"\"\"\n",
    "    image_clean = cv2.bilateralFilter(image, d=15, sigmaColor=50, sigmaSpace=5)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    image_clean = clahe.apply(image_clean)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (16, 16))\n",
    "    tophat = cv2.morphologyEx(image_clean, cv2.MORPH_BLACKHAT, kernel)\n",
    "\n",
    "    _, binary_top = cv2.threshold(tophat, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    contours, _ = cv2.findContours(binary_top, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    candidates = []\n",
    "    sizes = []\n",
    "    img_w, img_h = image.shape\n",
    "\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if min_area < area < max_area:\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            crop_x_start = x - offset\n",
    "            crop_x_end = x + w + offset\n",
    "            crop_y_start = y - offset\n",
    "            crop_y_end = y + h + offset\n",
    "\n",
    "            if crop_x_start < 0 or crop_x_end >= img_w or crop_y_start < 0 or crop_y_end >= img_h:\n",
    "                continue\n",
    "\n",
    "            patch = image[crop_y_start:crop_y_end, crop_x_start:crop_x_end]\n",
    "            candidates.append((patch, h, w))\n",
    "            sizes.append((h, w))\n",
    "\n",
    "    if not candidates:\n",
    "        raise ValueError(\"No valid dot candidates found.\")\n",
    "\n",
    "    # Compute median size\n",
    "    heights = [s[0] for s in sizes]\n",
    "    widths = [s[1] for s in sizes]\n",
    "    median_area = np.median(heights) * np.median(widths)\n",
    "\n",
    "    # Keep only patches with similar size\n",
    "    patches_filtered = []\n",
    "    resized_for_matching = []\n",
    "    for (patch, h, w) in candidates:\n",
    "        # print(abs(h * w - median_area))\n",
    "        if abs(h * w - median_area) / median_area < size_tol:\n",
    "            patches_filtered.append(patch)\n",
    "            resized_for_matching.append(cv2.resize(patch, patch_size))\n",
    "\n",
    "    if not patches_filtered:\n",
    "        raise ValueError(\"No size-consistent patches found.\")\n",
    "\n",
    "    # Find patch closest to the median template\n",
    "    stack = np.stack(resized_for_matching, axis=0).astype(np.float32)\n",
    "    median_template = np.median(stack, axis=0)\n",
    "    diffs = [np.linalg.norm(p.astype(np.float32) - median_template) for p in resized_for_matching]\n",
    "    best_idx = np.argmin(diffs)\n",
    "\n",
    "    return patches_filtered[best_idx], contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b33432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def template_matching(reflectance, template, method, match_thresh=0.7, nms_thresh=0.3):\n",
    "    \"\"\"\n",
    "    Perform template matching to find the best match for the template in the reflectance image.\n",
    "\n",
    "    Args:\n",
    "        reflectance: Input reflectance image (numpy array)\n",
    "        template: Template image (numpy array)\n",
    "        method: Method for template matching (default is cv2.TM_CCOEFF_NORMED)\n",
    "        match_thresh: Threshold for template matching (default is 0.7)\n",
    "        nms_thresh: Threshold for non-maximum suppression (default is 0.3)\n",
    "\n",
    "    Returns:\n",
    "        List of bounding boxes for the detected matches.\n",
    "    \"\"\"\n",
    "    # === Template matching ===\n",
    "    result = cv2.matchTemplate(reflectance, template, method)\n",
    "    locations = zip(*np.where(result >= match_thresh)[::-1])\n",
    "    scores = result[result >= match_thresh].flatten()\n",
    "\n",
    "    # === Bounding boxes (x, y, w, h) for each match ===\n",
    "    h, w = template.shape\n",
    "    boxes = [(int(x), int(y), w, h) for (x, y) in locations]\n",
    "\n",
    "    # === Apply NMS ===\n",
    "    nms_boxes = non_max_suppression_fast(boxes, scores, overlap_thresh=nms_thresh)\n",
    "\n",
    "    return nms_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779517b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contours_from_patch(patch):\n",
    "    \"\"\"\n",
    "    Extracts contours from supplied patch image.\n",
    "    \"\"\"\n",
    "    _, binary_patch = cv2.threshold(patch, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    contours, _ = cv2.findContours(binary_patch, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0027d493",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hu_descriptor(patch):\n",
    "    \"\"\"\n",
    "    Computes Hu moments for a given patch.\n",
    "\n",
    "    Args:\n",
    "        patch: Input patch (numpy array)\n",
    "    \n",
    "    Returns:\n",
    "        Hu moments of the patch (numpy array)\n",
    "    \"\"\"\n",
    "    contours = contours_from_patch(patch)\n",
    "    if not contours:\n",
    "        return np.zeros(7)\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    moments = cv2.moments(largest_contour)\n",
    "    hu_moments = cv2.HuMoments(moments).flatten()\n",
    "    return -np.sign(hu_moments) * np.log10(np.abs(hu_moments) + 1e-10)\n",
    "\n",
    "def select_diverse_templates(candidates, k):\n",
    "    \"\"\"\n",
    "    Selects k diverse templates from the candidates using greedy farthest-point sampling.\n",
    "\n",
    "    Args:\n",
    "        candidates: List of candidate patches (numpy arrays)\n",
    "        k: Number of templates to select\n",
    "    \n",
    "    Returns:\n",
    "        List of selected templates (numpy arrays)\n",
    "    \"\"\"\n",
    "    selected = [candidates[0]]\n",
    "    selected_ids = {id(candidates[0])}\n",
    "\n",
    "    while len(selected) < k and len(selected) < len(candidates):\n",
    "        remaining = [c for c in candidates if id(c) not in selected_ids]\n",
    "        if not remaining:\n",
    "            break\n",
    "        best = max(\n",
    "            remaining,\n",
    "            key=lambda c: min(np.linalg.norm(c[0] - s[0]) for s in selected)\n",
    "        )\n",
    "        selected.append(best)\n",
    "        selected_ids.add(id(best))\n",
    "\n",
    "    return [s[1] for s in selected] # return patches only\n",
    "\n",
    "def cascade_template_matching(reflectance, template, method, match_thresh=0.7, nms_thresh=0.3, k_templates=4, debug=False):\n",
    "    \"\"\"\n",
    "    Performs template matching repeatedly using new matches as templates until enough matches found.\n",
    "\n",
    "    Args:\n",
    "        reflectance: Input reflectance image (numpy array)\n",
    "        template: Template image (numpy array)\n",
    "        method: Method for template matching (default is cv2.TM_CCOEFF_NORMED)\n",
    "        match_thresh: Threshold for template matching (default is 0.7)\n",
    "        nms_thresh: Threshold for non-maximum suppression (default is 0.3)\n",
    "        debug: If True, display debug information (default is False)\n",
    "\n",
    "    Returns:\n",
    "        List of bounding boxes for the detected matches.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initial template matching\n",
    "    initial_boxes = template_matching(reflectance, template, method, match_thresh, nms_thresh)\n",
    "    if len(initial_boxes) == 0:\n",
    "        raise ValueError(\"No matches found in initial template matching.\")\n",
    "\n",
    "    h, w = template.shape\n",
    "    candidates = []\n",
    "    for box in initial_boxes:\n",
    "        x, y, bw, bh = box\n",
    "        patch = reflectance[y:y + bh, x:x + bw]\n",
    "        # resize patch to original template size\n",
    "        if patch.shape != template.shape:\n",
    "            patch = cv2.resize(patch, (w, h), interpolation=cv2.INTER_AREA)\n",
    "        descriptor = hu_descriptor(patch)\n",
    "        candidates.append((descriptor, patch, box))\n",
    "\n",
    "    if len(candidates) < k_templates:\n",
    "        k_templates = len(candidates)\n",
    "    \n",
    "    # select k diverse templates from the candidates\n",
    "    diverse_templates = select_diverse_templates(candidates, k_templates)\n",
    "\n",
    "    # accumulate boxes from new templates\n",
    "    all_boxes = list(initial_boxes)\n",
    "    for new_template in diverse_templates:\n",
    "        matches = template_matching(reflectance, new_template, method, match_thresh, nms_thresh)\n",
    "        all_boxes.extend(matches)\n",
    "    all_boxes = np.array(all_boxes)\n",
    "\n",
    "    # Apply NMS to the new boxes\n",
    "    all_scores = [1] * len(all_boxes) # optionally use actual scores\n",
    "    final_boxes = non_max_suppression_fast(all_boxes, all_scores, overlap_thresh=nms_thresh)\n",
    "\n",
    "    return final_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f710876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(image, size=(300, 300)):\n",
    "    \"\"\"\n",
    "    Displays the numpy image using PIL and notebook display functionality.\n",
    "\n",
    "    Args:\n",
    "        image: Input image (numpy array)\n",
    "        size: Size to which the image should be resized (default is (300, 300))\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, size)\n",
    "    pil_image = Image.fromarray(image)\n",
    "    display(pil_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a90c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_yucheng_methods(nms_boxes, reflectance, dot_contours, img, illumination, dot_template):\n",
    "    \"\"\"\n",
    "    Displays the results of Yuchengs methods for dot detection and template matching.\n",
    "\n",
    "    Args:\n",
    "        nms_boxes: List of bounding boxes after non-maximum suppression\n",
    "        reflectance: Reflectance map (numpy array)\n",
    "        dot_contours: Contours of the detected dots\n",
    "        img: Original image (numpy array)\n",
    "        illumination: Estimated illumination (numpy array)\n",
    "        dot_template: Dot template (numpy array)\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # === Draw matching result ===\n",
    "    output = cv2.cvtColor(reflectance, cv2.COLOR_GRAY2BGR)\n",
    "    for (x, y, w, h) in nms_boxes:\n",
    "        cv2.rectangle(output, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # === Draw contours over reflectance ===\n",
    "    contour_vis = cv2.cvtColor(reflectance, cv2.COLOR_GRAY2BGR)\n",
    "    cv2.drawContours(contour_vis, dot_contours, -1, (0, 0, 255), 1)\n",
    "\n",
    "    # === Show results ===\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(10, 6))\n",
    "    axs[0, 0].imshow(img, cmap='gray')\n",
    "    axs[0, 0].set_title(\"Original Image\")\n",
    "    axs[0, 0].axis(\"off\")\n",
    "\n",
    "    axs[0, 1].imshow(illumination, cmap='gray')\n",
    "    axs[0, 1].set_title(\"Estimated Illumination\")\n",
    "    axs[0, 1].axis(\"off\")\n",
    "\n",
    "    axs[0, 2].imshow(reflectance, cmap='gray')\n",
    "    axs[0, 2].set_title(\"Reflectance Map (SSR)\")\n",
    "    axs[0, 2].axis(\"off\")\n",
    "\n",
    "    axs[1, 0].imshow(cv2.cvtColor(contour_vis, cv2.COLOR_BGR2RGB))\n",
    "    axs[1, 0].set_title(\"Dot Contours\")\n",
    "    axs[1, 0].axis(\"off\")\n",
    "\n",
    "    axs[1, 1].imshow(dot_template, cmap='gray')\n",
    "    axs[1, 1].set_title(\"Dot template (median of patches)\")\n",
    "    axs[1, 1].axis(\"off\")\n",
    "\n",
    "    axs[1, 2].imshow(cv2.cvtColor(output, cv2.COLOR_BGR2RGB))\n",
    "    axs[1, 2].set_title(\"Template matching\")\n",
    "    axs[1, 2].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb86f39",
   "metadata": {},
   "source": [
    "## Yucheng Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be9f7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load image (grayscale) ===\n",
    "img_to_test = \"../data/delete.jpg\"\n",
    "template_to_test = \"../data/delete_template.jpg\"\n",
    "img = cv2.imread(img_to_test, cv2.IMREAD_GRAYSCALE)\n",
    "img = cv2.resize(img, (320, 320))\n",
    "dot_template = cv2.imread(template_to_test, cv2.IMREAD_GRAYSCALE)\n",
    "dot_template = cv2.resize(dot_template, (19, 19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cf6b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Apply Retinex ===\n",
    "reflectance, illumination = single_scale_retinex(img, sigma=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec23de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_contours = contours_from_patch(dot_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdfe8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # === Extract dominant template and contours ===\n",
    "# # REPLACE WITH YOUR ACTUAL TEMPLATE\n",
    "# dot_template, dot_contours = extract_dominant_dot_template(reflectance,\n",
    "#                                                            min_area=20,\n",
    "#                                                            max_area=300,\n",
    "#                                                            patch_size=(24, 24),\n",
    "#                                                            offset=5,\n",
    "#                                                            size_tol=0.5)\n",
    "\n",
    "# display_image(dot_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28386d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cascade template matching ===\n",
    "nms_boxes = cascade_template_matching(reflectance, dot_template, method=cv2.TM_CCOEFF_NORMED, match_thresh=0.7, nms_thresh=0.3, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f9db89",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_yucheng_methods(nms_boxes, reflectance, dot_contours, img, illumination, dot_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2725a5",
   "metadata": {},
   "source": [
    "# Grid Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc81c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_grid(params, grid_size=16):\n",
    "    \"\"\"\n",
    "    Generates a grid of DMC points based on the given parameters.\n",
    "\n",
    "    Args:\n",
    "        x0: X coordinate of the center of the grid\n",
    "        y0: Y coordinate of the center of the grid\n",
    "        sx: Scale factor in the X direction\n",
    "        sy: Scale factor in the Y direction\n",
    "        theta: Rotation angle in radians\n",
    "        grid_size: Size of the grid (default is 16)\n",
    "    \n",
    "    Returns:\n",
    "        array of grid points (x, y) in the original coordinate system\n",
    "    \"\"\"\n",
    "    x0, y0, sx, sy, theta = params\n",
    "\n",
    "    # force sx and sy to be minimum of 1.0 (to avoid zero size)\n",
    "    sx = max(sx, 1.0)\n",
    "    sy = max(sy, 1.0)\n",
    "\n",
    "    # building standard grid of DMC points (finder pattern + all inner points)\n",
    "    coords = []\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            # finder pattern specific points\n",
    "            if 0 in [i, j] or grid_size - 1 in [i, j]: # points on the finder pattern\n",
    "                if j == 0 and i in range(1, grid_size - 1, 2): # top timing pattern\n",
    "                    continue\n",
    "                elif i == grid_size - 1 and j in range(0, grid_size - 1, 2): # right timing pattern\n",
    "                    continue\n",
    "                else: # left and bottom finder pattern\n",
    "                    coords.append([i, j])\n",
    "            else: # inner points\n",
    "                coords.append([i, j])\n",
    "    coords = np.array(coords).astype(float)\n",
    "\n",
    "    # center the grid around (0, 0)\n",
    "    coords -= (grid_size - 1) / 2\n",
    "\n",
    "    # Convert to original coordinate system\n",
    "    coords = np.dot(coords, np.array([[sx, 0], [0, sy]])) # scale\n",
    "    coords = np.dot(coords, np.array([[np.cos(theta), -np.sin(theta)], [np.sin(theta), np.cos(theta)]])) # rotate\n",
    "    coords += np.array([[x0, y0]]) # translate\n",
    "\n",
    "    return coords\n",
    "\n",
    "def inverse_grid_transform(grid_pts, params, grid_size=16):\n",
    "    \"\"\"\n",
    "    Inverse transformation of the grid points to the original coordinate system.\n",
    "\n",
    "    Args:\n",
    "        grid_pts: Grid points to be transformed (numpy array)\n",
    "        params: Parameters used for the transformation (x0, y0, sx, sy, theta)\n",
    "        grid_size: Size of the grid (default is 16)\n",
    "\n",
    "    Returns:\n",
    "        array of grid points (x, y) in the dmc coordinate system\n",
    "    \"\"\"\n",
    "    x0, y0, sx, sy, theta = params\n",
    "\n",
    "    # force sx and sy to be minimum of 1.0 (same as in generate_grid)\n",
    "    sx = max(sx, 1.0)\n",
    "    sy = max(sy, 1.0)\n",
    "\n",
    "    # undo translation\n",
    "    grid_pts = grid_pts.astype(float)\n",
    "    grid_pts -= np.array([[x0, y0]])\n",
    "\n",
    "    # undo rotation\n",
    "    rot_mat_inv = np.array([[np.cos(theta), np.sin(theta)],\n",
    "                            [-np.sin(theta), np.cos(theta)]])\n",
    "    grid_pts = np.dot(grid_pts, rot_mat_inv)\n",
    "\n",
    "    # undo scaling\n",
    "    grid_pts = np.dot(grid_pts, np.linalg.inv(np.diag([sx, sy])))\n",
    "\n",
    "    # convert to standard grid coordinates\n",
    "    grid_pts += (grid_size - 1) / 2\n",
    "\n",
    "    # round to nearest integer\n",
    "    grid_pts = np.rint(grid_pts).astype(int)\n",
    "\n",
    "    # clip to valid range (to avoid errors)\n",
    "    if np.any(grid_pts < 0) or np.any(grid_pts >= grid_size):\n",
    "        print(\"Warning: one or more grid points are out of bounds!\")\n",
    "        grid_pts = np.clip(grid_pts, 0, grid_size - 1)\n",
    "\n",
    "    return grid_pts\n",
    "\n",
    "\n",
    "def show_grid(img, grid_pts, title=\"Grid Points\"):\n",
    "    \"\"\"\n",
    "    Shows the grid points on the image.\n",
    "\n",
    "    Args:\n",
    "        img: Input image (numpy array)\n",
    "        grid_pts: Grid points to be displayed (numpy array)\n",
    "        title: Title of the plot (default is \"Grid Points\")\n",
    "    \"\"\"\n",
    "    img = img.copy() # to avoid modifying the original image\n",
    "    if len(img.shape) == 2 or img.shape[2] == 1:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)  # Convert grayscale to BGR\n",
    "    for p in grid_pts:\n",
    "        # cv2.circle(img, (int(p[0]), int(p[1])), 3, (0, 255, 0), -1)\n",
    "        cv2.circle(img, (int(p[0]), int(p[1])), 3, (0, 0, 255), -1) # red color for grid points\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# === Example usage of grid generation ===\n",
    "img = cv2.imread(img_to_test, cv2.IMREAD_GRAYSCALE)\n",
    "img = cv2.resize(img, (320, 320))\n",
    "\n",
    "# params to cover entire image\n",
    "img_size = img.shape[0]\n",
    "params = [\n",
    "    img_size / 2, # x0\n",
    "    img_size / 2, # y0\n",
    "    img_size / 15, # sx\n",
    "    img_size / 15, # sy\n",
    "    0.0 # theta\n",
    "]\n",
    "grid_pts = generate_grid(params)\n",
    "show_grid(img, grid_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9063e81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_grid_params(nms_boxes, debug=False):\n",
    "    \"\"\"\n",
    "    Estimates grid starting parameters using the observed points from the detected boxes.\n",
    "    The function uses the observed points to compute the initial parameters for the affine transformation.\n",
    "    \"\"\"\n",
    "    observed_pts = np.array([[x + w / 2, y + h / 2] for (x, y, w, h) in nms_boxes])\n",
    "\n",
    "    # estimating reasonable x, y based on the average of all points\n",
    "    x = np.mean(observed_pts[:, 0])\n",
    "    y = np.mean(observed_pts[:, 1])\n",
    "    if debug:\n",
    "        print(f\"Estimated x, y: ({x}, {y})\")\n",
    "\n",
    "    # getting mode distance between closest points for later usage\n",
    "    distances = []\n",
    "    for i in range(len(observed_pts)):\n",
    "        closest_pt = float('inf')\n",
    "        for j in range(i + 1, len(observed_pts)):\n",
    "            if i != j:\n",
    "                # find the closest point to i\n",
    "                dist = np.linalg.norm(observed_pts[i] - observed_pts[j])\n",
    "                if dist < closest_pt:\n",
    "                    closest_pt = dist\n",
    "        if closest_pt != float('inf'):\n",
    "            distances.append(np.round(closest_pt, 2))\n",
    "    # mode distance is used because we want the most common distance, not the average\n",
    "    mod_dist = get_mode(distances)\n",
    "    if debug:\n",
    "        print(f\"Modal distance between (close) points: {mod_dist}\")\n",
    "\n",
    "    # estimating sx & sy based on vectors of points and their closest \"L\" neighbors (points at distances of mod_dist or less)\n",
    "    # simultaneously estimating theta based on the angle between the two vectors\n",
    "    sxs = []\n",
    "    sys = []\n",
    "    thetas = []\n",
    "    for i in range(len(observed_pts)):\n",
    "        # find closest point to i\n",
    "        dist_a = float('inf')\n",
    "        a_idx = -1\n",
    "        for j in range(i + 1, len(observed_pts)):\n",
    "            dist = np.linalg.norm(observed_pts[i] - observed_pts[j])\n",
    "            if dist < dist_a:\n",
    "                dist_a = dist\n",
    "                a_idx = j\n",
    "                point_a = observed_pts[j]\n",
    "                vec_a = observed_pts[j] - observed_pts[i]\n",
    "        \n",
    "        # find next closest point to i that forms a tight enough \"L\" shape with regards to first point\n",
    "        # (i.e. the two points are orthogonal to each other from i)\n",
    "        point_b = None\n",
    "        for j in range(i + 1, len(observed_pts)):\n",
    "            if j == a_idx:\n",
    "                continue\n",
    "            \n",
    "            # check if vectors from point i to point_a and from i to point_b are orthogonal\n",
    "            vec_b_tmp = observed_pts[j] - observed_pts[i]\n",
    "            cos_angle = np.dot(vec_a, vec_b_tmp) / (np.linalg.norm(vec_a) * np.linalg.norm(vec_b_tmp) + 1e-8)\n",
    "            angle_deg = np.degrees(np.arccos(np.clip(cos_angle, -1.0, 1.0)))\n",
    "            if 80 <= angle_deg <= 100:\n",
    "                # points i, a_idx, and j form an \"L\" shape!\n",
    "                # now to make sure both points are close enough to i\n",
    "                dist_b = np.linalg.norm(vec_b_tmp)\n",
    "                if dist_a <= mod_dist*2 and dist_b <= mod_dist*2:\n",
    "                    # point_b is close enough to i!\n",
    "                    point_b = observed_pts[j]\n",
    "                    vec_b = vec_b_tmp\n",
    "                    # if debug:\n",
    "                        # print(f\"Found L shape: {observed_pts[i]} -> {point_a} -> {point_b}\")\n",
    "                        # print(f\"Vectors: {vec_a}, {vec_b}\")\n",
    "                        # print(f\"Distances: {np.linalg.norm(vec_a)}, {np.linalg.norm(vec_b)}\")\n",
    "        \n",
    "        # if we found a point that is orthogonal to point_a, we can use it to estimate sx and sy\n",
    "        if point_a is not None and point_b is not None:\n",
    "            # stricter dist check for sx and sy than theta\n",
    "            # we can use the distance between the points to estimate sx and sy\n",
    "            if dist_a <= mod_dist and dist_b <= mod_dist:\n",
    "                sx_a = np.linalg.norm(vec_a)\n",
    "                sx_b = np.linalg.norm(vec_b)\n",
    "                \n",
    "                # round to 2 decimal places for consistent mode calculation\n",
    "                sx_a = np.round(sx_a, 2)\n",
    "                sx_b = np.round(sx_b, 2)\n",
    "\n",
    "                # weird case where numpy differentiates between -0.0 and 0.0\n",
    "                if sx_a == 0:\n",
    "                    sx_a = 0\n",
    "                if sx_b == 0:\n",
    "                    sx_b = 0\n",
    "\n",
    "                sxs.append(sx_a)\n",
    "                sys.append(sx_b)\n",
    "                \n",
    "                # sxs.append(np.linalg.norm(vec_a))\n",
    "                # sys.append(np.linalg.norm(vec_b))\n",
    "            # we can also compare angle between the two vectors and default vector (0, 1)\n",
    "            theta_a = np.arctan2(vec_a[1], vec_a[0]) - np.arctan2(0, 1)\n",
    "            theta_b = np.arctan2(vec_b[1], vec_b[0]) - np.arctan2(0, 1)\n",
    "            # for consistency, we want to use the angle of the vector that is closest to the default vector (0, 1)\n",
    "            if abs(theta_a) < abs(theta_b):\n",
    "                theta = theta_a\n",
    "            else:\n",
    "                theta = theta_b\n",
    "            theta = np.round(theta, 2) # round to 2 decimal places for consistent mode calculation\n",
    "            if theta == 0: # weird case where numpy differentiates between -0.0 and 0.0\n",
    "                theta = 0\n",
    "            thetas.append(-theta) # flipped angle\n",
    "            # if debug:\n",
    "            #     print(f\"Angle: {theta}\")\n",
    "\n",
    "                # plot found L shapes\n",
    "                # plt.plot([observed_pts[i][0], point_a[0]], [observed_pts[i][1], point_a[1]], 'r-')\n",
    "                # plt.plot([observed_pts[i][0], point_b[0]], [observed_pts[i][1], point_b[1]], 'r-')\n",
    "                # plt.plot([point_a[0], point_b[0]], [point_a[1], point_b[1]], 'r-')\n",
    "                # plt.scatter(observed_pts[i][0], observed_pts[i][1], color='blue')\n",
    "                # plt.scatter(point_a[0], point_a[1], color='green')\n",
    "                # plt.scatter(point_b[0], point_b[1], color='green')\n",
    "                # plt.xlim(0, img.shape[1])\n",
    "                # plt.ylim(img.shape[0], 0)\n",
    "                # plt.title(\"L shape\")\n",
    "                # plt.show()\n",
    "    # take the mode of the distances to estimate sx and sy. if no L shapes are found, use the overall modal distance\n",
    "    if len(sxs) > 0:\n",
    "        sx = get_mode(sxs)\n",
    "        sy = get_mode(sys)\n",
    "    else:\n",
    "        sx = mod_dist\n",
    "        sy = mod_dist\n",
    "        theta = 0\n",
    "    if debug:\n",
    "        print(f\"Estimated sx & sy: {sx}, {sy}\")\n",
    "\n",
    "    theta = get_mode(thetas) # use mode for theta to avoid outliers\n",
    "    if debug:\n",
    "        print(f\"Estimated theta: {theta}\")\n",
    "\n",
    "    init_params = [x, y, sx, sy, theta]\n",
    "    if debug:\n",
    "        print(f\"Initial parameters: {init_params}\")\n",
    "\n",
    "    return init_params, observed_pts\n",
    "\n",
    "# === Example usage of grid parameter estimation ===\n",
    "img = cv2.imread(img_to_test, cv2.IMREAD_GRAYSCALE)\n",
    "img = cv2.resize(img, (320, 320))\n",
    "nms_boxes = [(x, y, w, h) for (x, y, w, h) in nms_boxes]\n",
    "init_params, observed_pts = estimate_grid_params(nms_boxes, debug=True)\n",
    "grid_pts = generate_grid(init_params)\n",
    "show_grid(img, grid_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d78d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_convex_hull(observed_points, grid_points=None):\n",
    "    hull = ConvexHull(observed_points)\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.plot(observed_points[:, 0], observed_points[:, 1], 'o', label='Observed Points')\n",
    "\n",
    "    # Draw convex hull edges\n",
    "    for simplex in hull.simplices:\n",
    "        plt.plot(observed_points[simplex, 0], observed_points[simplex, 1], 'k-')\n",
    "\n",
    "    # Optionally plot grid points\n",
    "    if grid_points is not None:\n",
    "        plt.plot(grid_points[:, 0], grid_points[:, 1], 'rx', label='Grid Points')\n",
    "\n",
    "    plt.title(\"Observed Points and Convex Hull\")\n",
    "    plt.legend()\n",
    "    plt.axis('equal')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025ed101",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(params, observed_points, N, alpha):\n",
    "    \"\"\"\n",
    "    Cost function for optimization. It computes the mean squared distance between observed points and grid points.\n",
    "    The loss function is robust to outliers by focusing on the N closest points.\n",
    "\n",
    "    Args:\n",
    "        params: Parameters for grid (x0, y0, sx, sy, theta)\n",
    "        observed_points: Observed points (numpy array)\n",
    "        N: Number of closest points to consider for cost function\n",
    "        alpha: Weighting factor for the cost function\n",
    "    \n",
    "    Returns:\n",
    "        Mean squared distance between observed points and grid points.\n",
    "    \"\"\"\n",
    "    grid_points = generate_grid(params)\n",
    "\n",
    "    center = np.mean(observed_points, axis=0)\n",
    "    distances_from_center = np.linalg.norm(observed_points - center, axis=1)\n",
    "    \n",
    "    # compute weights based on distance from center\n",
    "    mean_distance = np.mean(distances_from_center)\n",
    "    normalized_distances = distances_from_center / mean_distance\n",
    "    weights = normalized_distances ** alpha\n",
    "\n",
    "    # normalize weights to have mean 1\n",
    "    weights = weights / np.mean(weights)\n",
    "\n",
    "    all_N_closest_dists = []\n",
    "    for i, obs_point in enumerate(observed_points):\n",
    "        # finding N closest dists to point\n",
    "        dists = np.linalg.norm(obs_point - grid_points, axis=1)\n",
    "        sorted_dists = np.sort(dists)\n",
    "        closest_dists = sorted_dists[:N]\n",
    "\n",
    "        # \n",
    "        weighted_squared_dist = weights[i] * (closest_dists ** 2)\n",
    "        all_N_closest_dists.extend(weighted_squared_dist)\n",
    "\n",
    "    cost_ = np.mean(all_N_closest_dists)\n",
    "\n",
    "    return cost_\n",
    "\n",
    "# === Example usage of cost function ===\n",
    "img = cv2.imread(img_to_test, cv2.IMREAD_GRAYSCALE)\n",
    "img = cv2.resize(img, (320, 320))\n",
    "nms_boxes = [(x, y, w, h) for (x, y, w, h) in nms_boxes]\n",
    "N = 1000 # number of closest points to consider for cost function (higher = better, but slower)\n",
    "alpha = 1.0\n",
    "\n",
    "# cost of grid covering entire image\n",
    "params = [\n",
    "    img.shape[0] / 2, # x0\n",
    "    img.shape[0] / 2, # y0\n",
    "    img.shape[0] / 15, # sx\n",
    "    img.shape[0] / 15, # sy\n",
    "    0.0 # theta\n",
    "]\n",
    "grid_pts = generate_grid(params)\n",
    "show_grid(img, grid_pts)\n",
    "observed_pts = np.array([[x + w / 2, y + h / 2] for (x, y, w, h) in nms_boxes])\n",
    "cost_value = cost(params, observed_pts, N, alpha)\n",
    "print(f\"Cost value (naive start): {cost_value}\")\n",
    "\n",
    "init_params, observed_pts = estimate_grid_params(nms_boxes, debug=False)\n",
    "grid_pts = generate_grid(init_params)\n",
    "show_grid(img, grid_pts)\n",
    "cost_value = cost(init_params, observed_pts, N, alpha)\n",
    "print(f\"Cost value (estimated start): {cost_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33131f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_xy(xy, params, observed_pts, N, alpha):\n",
    "    \"\"\"\n",
    "    Wrapper function for cost function. It takes the xy coordinates and the rest of the parameters separately.\n",
    "    Used for optimizing x0 and y0.\n",
    "\n",
    "    Args:\n",
    "        xy: X and Y coordinates of the center of the grid\n",
    "        params: Parameters for grid (sx, sy, theta)\n",
    "    \n",
    "    Returns:\n",
    "        Mean squared distance between observed points and grid points.\n",
    "    \"\"\"\n",
    "    x0, y0 = xy\n",
    "    sx, sy, theta = params\n",
    "    return cost([x0, y0, sx, sy, theta], observed_pts, N, alpha)\n",
    "\n",
    "def cost_sx_sy(sx_sy, params, observed_pts, N, alpha):\n",
    "    \"\"\"\n",
    "    Wrapper function for cost function. It takes the sx and sy coordinates and the rest of the parameters separately.\n",
    "    Used for optimizing sx and sy.\n",
    "\n",
    "    Args:\n",
    "        sx_sy: Scale factors in the X and Y directions\n",
    "        params: Parameters for grid (x0, y0, theta)\n",
    "    \n",
    "    Returns:\n",
    "        Mean squared distance between observed points and grid points.\n",
    "    \"\"\"\n",
    "    sx, sy = sx_sy\n",
    "    x0, y0, theta = params\n",
    "    return cost([x0, y0, sx, sy, theta], observed_pts, N, alpha)\n",
    "\n",
    "def cost_theta(theta, params, observed_pts, N, alpha):\n",
    "    \"\"\"\n",
    "    Wrapper function for cost function. It takes the theta coordinate and the rest of the parameters separately.\n",
    "    Used for optimizing theta.\n",
    "\n",
    "    Args:\n",
    "        theta: Rotation angle in radians\n",
    "        params: Parameters for grid (x0, y0, sx, sy)\n",
    "    \n",
    "    Returns:\n",
    "        Mean squared distance between observed points and grid points.\n",
    "    \"\"\"\n",
    "    theta = theta[0]  # Extract the single value from the array\n",
    "    x0, y0, sx, sy = params\n",
    "    return cost([x0, y0, sx, sy, theta], observed_pts, N, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455b06ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_grid(init_params, observed_pts, img, N, alpha, debug=False):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    x0, y0, sx, sy, theta = init_params\n",
    "\n",
    "    # 0. check for better initial theta\n",
    "    # trying other 3 90 degree angles to see if they are better\n",
    "    lowest_cost = cost([x0, y0, sx, sy, theta], observed_pts, N, alpha)\n",
    "    for i in range(1, 4):\n",
    "        theta_tmp = (theta + i * np.pi / 2) % (2 * np.pi)\n",
    "        theta_tmp_cost = cost([x0, y0, sx, sy, theta_tmp], observed_pts, N, alpha)\n",
    "        if theta_tmp_cost < lowest_cost:\n",
    "            lowest_cost = theta_tmp_cost\n",
    "            theta = theta_tmp\n",
    "    if debug:\n",
    "        print(f\"Better initial theta found: {theta}\")\n",
    "        print(f\"Cost value: {cost([x0, y0, sx, sy, theta], observed_pts, N, alpha)}\")\n",
    "        show_grid(img, generate_grid([x0, y0, sx, sy, theta]), title=\"Initial Estimate\")\n",
    "\n",
    "    # 1. optimize for x0, y0 only\n",
    "    result = minimize(cost_xy, [x0, y0], args=([sx, sy, theta], observed_pts, N, alpha), method='Powell')\n",
    "    x0, y0 = result.x\n",
    "    if debug:\n",
    "        print(f\"Optimized x0, y0: {x0}, {y0}\")\n",
    "        print(f\"Cost value: {cost([x0, y0, sx, sy, theta], observed_pts, N, alpha)}\")\n",
    "        show_grid(img, generate_grid([x0, y0, sx, sy, theta]), title=\"Optimized x0, y0\")\n",
    "    \n",
    "    # 2. optimize for sx, sy only\n",
    "    result = minimize(cost_sx_sy, [sx, sy], args=([x0, y0, theta], observed_pts, N, alpha), method='Powell')\n",
    "    sx, sy = result.x\n",
    "    if debug:\n",
    "        print(f\"Optimized sx, sy: {sx}, {sy}\")\n",
    "        print(f\"Cost value: {cost([x0, y0, sx, sy, theta], observed_pts, N, alpha)}\")\n",
    "        show_grid(img, generate_grid([x0, y0, sx, sy, theta]), title=\"Optimized sx, sy\")\n",
    "\n",
    "    # 3. optimize for theta only\n",
    "    result = minimize(cost_theta, [theta], args=([x0, y0, sx, sy], observed_pts, N, alpha), method='Powell')\n",
    "    theta = result.x[0]\n",
    "    # trying other 3 90 degree angles to see if they are better\n",
    "    lowest_cost = cost([x0, y0, sx, sy, theta], observed_pts, N, alpha)\n",
    "    for i in range(1, 4):\n",
    "        theta_tmp = (theta + i * np.pi / 2) % (2 * np.pi)\n",
    "        theta_tmp_cost = cost([x0, y0, sx, sy, theta_tmp], observed_pts, N, alpha)\n",
    "        if theta_tmp_cost < lowest_cost:\n",
    "            if debug:\n",
    "                print(f\"Found better theta: {theta_tmp} with cost: {theta_tmp_cost}. (previous: {theta} with cost: {lowest_cost})\")\n",
    "            lowest_cost = theta_tmp_cost\n",
    "            theta = theta_tmp\n",
    "    if debug:\n",
    "        print(f\"Optimized theta: {theta}\")\n",
    "        print(f\"Cost value: {cost([x0, y0, sx, sy, theta], observed_pts, N, alpha)}\")\n",
    "        show_grid(img, generate_grid([x0, y0, sx, sy, theta]), title=\"Optimized theta\")\n",
    "\n",
    "    # 4. optimize for all parameters together\n",
    "    result = minimize(cost, [x0, y0, sx, sy, theta], args=(observed_pts, N, alpha), method='Powell')\n",
    "    x0, y0, sx, sy, theta = result.x\n",
    "    if debug:\n",
    "        print(f\"Optimized all: {x0}, {y0}, {sx}, {sy}, {theta}\")\n",
    "        print(f\"Cost value: {cost([x0, y0, sx, sy, theta], observed_pts, N, alpha)}\")\n",
    "        show_grid(img, generate_grid([x0, y0, sx, sy, theta]), title=\"Optimized all\")\n",
    "\n",
    "    return [x0, y0, sx, sy, theta], observed_pts\n",
    "\n",
    "# === Example usage of grid estimation ===\n",
    "N = 1\n",
    "alpha = 5.0 # weight for cost function\n",
    "\n",
    "init_params, observed_pts = estimate_grid_params(nms_boxes, debug=False)\n",
    "print(f\"Initial parameters: {init_params}\")\n",
    "grid_pts = generate_grid(init_params)\n",
    "show_grid(img, grid_pts)\n",
    "opt_params, observed_pts = estimate_grid(init_params, observed_pts, img, N, alpha, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b449422b",
   "metadata": {},
   "source": [
    "# Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83588311",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_observed_to_grid(observed_pts, grid_pts):\n",
    "    \"\"\"\n",
    "    Maps observed points to grid points using the Hungarian algorithm to ensure 1-1 mapping.\n",
    "\n",
    "    Args:\n",
    "        observed_pts: Observed points (numpy array)\n",
    "        grid_pts: Grid points (numpy array)\n",
    "    \n",
    "    Returns:\n",
    "        Mapped grid points (numpy array)\n",
    "    \"\"\"\n",
    "    cost_matrix = cdist(observed_pts, grid_pts, metric='euclidean')\n",
    "    row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "    mapped_grid_pts = grid_pts[col_ind]\n",
    "    return mapped_grid_pts\n",
    "\n",
    "# === Example usage of mapping observed points to grid points ===\n",
    "img = cv2.imread(img_to_test, cv2.IMREAD_GRAYSCALE)\n",
    "img = cv2.resize(img, (320, 320))\n",
    "nms_boxes = [(x, y, w, h) for (x, y, w, h) in nms_boxes]\n",
    "init_params, observed_pts = estimate_grid_params(nms_boxes, debug=False)\n",
    "grid_pts = generate_grid(init_params)\n",
    "mapped_grid_pts = map_observed_to_grid(observed_pts, grid_pts)\n",
    "show_grid(img, mapped_grid_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92542d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dmc_matrix(dmc_pts, grid_size=16):\n",
    "    \"\"\"\n",
    "    Converts DMC points to a matrix representation.\n",
    "\n",
    "    Args:\n",
    "        dmc_pts: DMC points (numpy array)\n",
    "        grid_size: Size of the grid (default is 16)\n",
    "    \n",
    "    Returns:\n",
    "        DMC matrix (numpy array)\n",
    "    \"\"\"\n",
    "    dmc_matrix = np.zeros((grid_size, grid_size), dtype=int)\n",
    "    for pt in dmc_pts:\n",
    "        x, y = pt\n",
    "        dmc_matrix[y, x] = 1\n",
    "    return dmc_matrix\n",
    "\n",
    "# === Example usage of mapping to DMC points ===\n",
    "img = cv2.imread(img_to_test, cv2.IMREAD_GRAYSCALE)\n",
    "img = cv2.resize(img, (320, 320))\n",
    "nms_boxes = [(x, y, w, h) for (x, y, w, h) in nms_boxes]\n",
    "init_params, observed_pts = estimate_grid_params(nms_boxes, debug=False)\n",
    "grid_pts = generate_grid(init_params)\n",
    "mapped_grid_pts = map_observed_to_grid(observed_pts, grid_pts)\n",
    "dmc_pts = inverse_grid_transform(mapped_grid_pts, init_params)\n",
    "dmc_matrix = to_dmc_matrix(dmc_pts)\n",
    "print(\"DMC matrix:\")\n",
    "print(dmc_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f3488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_DMC(matrix):\n",
    "    \"\"\"\n",
    "    Display the DMC matrix like normal DMC.\n",
    "\n",
    "    Args:\n",
    "        matrix: Numpy array representing the DMC matrix\n",
    "    \"\"\"\n",
    "    # Invert the matrix for display\n",
    "    matrix = np.invert(matrix)\n",
    "    plt.imshow(matrix, cmap='gray', interpolation='nearest')\n",
    "    plt.title(\"DMC Matrix\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea99af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_DMC(matrix):\n",
    "    \"\"\"\n",
    "    Decodes the DMC matrix using pylibdmtx.\n",
    "\n",
    "    Args:\n",
    "        matrix: Numpy array representing the DMC matrix\n",
    "    \n",
    "    Returns:\n",
    "        \n",
    "    \"\"\"\n",
    "    # Converting binary matrix to uint8 image\n",
    "    image = np.zeros((matrix.shape[0], matrix.shape[1]), dtype=np.uint8)\n",
    "    image[matrix == 1] = 255\n",
    "    image = Image.fromarray(image, 'L')\n",
    "\n",
    "    # Inverting the image for decoding\n",
    "    image = Image.eval(image, lambda x: 255 - x)\n",
    "\n",
    "    # Padding the image by 2 pixels to add margin larger than a DMC module (https://www.keyence.eu/ss/products/auto_id/codereader/basic_2d/datamatrix.jsp)\n",
    "    image = np.pad(np.array(image), ((2, 2), (2, 2)), mode='constant', constant_values=255)\n",
    "    image = Image.fromarray(image, 'L')\n",
    "\n",
    "    # Resizing to larger image for better decoding\n",
    "    image = image.resize((image.size[0] * 10, image.size[1] * 10), Image.NEAREST)\n",
    "\n",
    "    # Decode using pylibdmtx\n",
    "    decoded = decode(image)\n",
    "    if decoded:\n",
    "        return decoded[0].data.decode('utf-8')\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d695c8c",
   "metadata": {},
   "source": [
    "# Example of Grid Fitting Followed by Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b12085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Estimate initial grid parameters ===\n",
    "init_params, observed_pts = estimate_grid_params(nms_boxes)\n",
    "grid_pts = generate_grid(init_params)\n",
    "show_grid(img, grid_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b8be7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Optimize grid parameters ===\n",
    "opt_params, observed_pts = estimate_grid(init_params, observed_pts, img, N, alpha)\n",
    "grid_pts = generate_grid(opt_params)\n",
    "show_grid(img, grid_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976b76e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Mapping observed points to grid points ===\n",
    "mapped_grid_pts = map_observed_to_grid(observed_pts, grid_pts)\n",
    "show_grid(img, mapped_grid_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ce1404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Convert to DMC matrix ===\n",
    "dmc_pts = inverse_grid_transform(mapped_grid_pts, opt_params)\n",
    "dmc_matrix = to_dmc_matrix(dmc_pts)\n",
    "display_DMC(dmc_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73d735d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Decoding DMC ===\n",
    "decoded_data = decode_DMC(dmc_matrix)\n",
    "print(decoded_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcff2487",
   "metadata": {},
   "source": [
    "# Full Decoding Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7262d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_pipeline(image_path, template_path, tm_method=cv2.TM_CCOEFF_NORMED, tmm_thresh=0.7, nms_thresh=0.3, k_templates=3, N=1, alpha=4.0, debug=False, rotation=None):\n",
    "    \"\"\"\n",
    "    Performs the entire decoding pipeline on the input image and template.\n",
    "\n",
    "    Args:\n",
    "        image_path: Path to the input image\n",
    "        template_path: Path to the template image\n",
    "        tm_method: Method for template matching (default is cv2.TM_CCOEFF_NORMED)\n",
    "        tmm_thresh: Threshold for template matching (default is 0.7)\n",
    "        nms_thresh: Threshold for non-maximum suppression (default is 0.3)\n",
    "        N: Number of closest points to consider for cost function (default is 1)\n",
    "        alpha: Weighting factor for the cost function (default is 4.0)\n",
    "        debug: Flag for debugging (default is False)\n",
    "        rotation: Rotation angle in degrees (default is None, no rotation)\n",
    "    \n",
    "    Returns:\n",
    "        Decoded data from the DMC matrix or None if decoding fails.\n",
    "    \"\"\"\n",
    "    # === Load image (grayscale) ===\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (320, 320))\n",
    "    dot_template = cv2.imread(template_path, cv2.IMREAD_GRAYSCALE)\n",
    "    dot_template = cv2.resize(dot_template, (19, 19))\n",
    "\n",
    "    # === Rotation ===\n",
    "    if rotation is not None:\n",
    "        h, w = img.shape\n",
    "        center = (w / 2, h / 2)\n",
    "\n",
    "        # rotation matrix\n",
    "        M = cv2.getRotationMatrix2D(center, rotation, 1)\n",
    "\n",
    "        # getting size of new box to avoid cutting off corners\n",
    "        cos = np.abs(M[0, 0])\n",
    "        sin = np.abs(M[0, 1])\n",
    "        new_w = int(h * sin + w * cos)\n",
    "        new_h = int(h * cos + w * sin)\n",
    "\n",
    "        # adjusting the rotation matrix to take into account translation\n",
    "        M[0, 2] += new_w / 2 - center[0]\n",
    "        M[1, 2] += new_h / 2 - center[1]\n",
    "\n",
    "        # rotating with new bounds\n",
    "        img = cv2.warpAffine(img, M, (new_w, new_h))\n",
    "\n",
    "    # === Apply Retinex ===\n",
    "    reflectance, illumination = single_scale_retinex(img, sigma=64)\n",
    "\n",
    "    # === Extract dot contours ===\n",
    "    dot_contours = contours_from_patch(dot_template)\n",
    "\n",
    "    # === Template matching ===\n",
    "    nms_boxes = cascade_template_matching(reflectance, dot_template, method=tm_method, match_thresh=tmm_thresh, nms_thresh=nms_thresh, k_templates=k_templates, debug=debug)\n",
    "    # nms_boxes = template_matching(reflectance, dot_template, method=tm_method, match_thresh=tmm_thresh, nms_thresh=nms_thresh)\n",
    "\n",
    "    if debug:\n",
    "        display_yucheng_methods(nms_boxes, reflectance, dot_contours, img, illumination, dot_template)\n",
    "\n",
    "    # === Estimate initial grid parameters ===\n",
    "    init_params, observed_pts = estimate_grid_params(nms_boxes, debug)\n",
    "    if debug:\n",
    "        print(f\"Initial parameters: {init_params}\")\n",
    "        grid_pts = generate_grid(init_params)\n",
    "        show_grid(img, grid_pts)\n",
    "\n",
    "    # === Optimizing Grid Parameters ===\n",
    "    opt_params, observed_pts = estimate_grid(init_params, observed_pts, img, N, alpha, debug)\n",
    "    grid_pts = generate_grid(opt_params)\n",
    "\n",
    "    # === Mapping observed points to grid points ===\n",
    "    mapped_grid_pts = map_observed_to_grid(observed_pts, grid_pts)\n",
    "    if debug:\n",
    "        print(f\"Mapped grid points\")\n",
    "        show_grid(img, mapped_grid_pts, title=\"Mapped\")\n",
    "\n",
    "    # === Convert to DMC matrix ===\n",
    "    dmc_pts = inverse_grid_transform(mapped_grid_pts, opt_params)\n",
    "    dmc_matrix = to_dmc_matrix(dmc_pts)\n",
    "    if debug:\n",
    "        print(\"DMC matrix pre fix\")\n",
    "        display_DMC(dmc_matrix)\n",
    "\n",
    "    # === Extra fix for finder patter ===\n",
    "    dmc_matrix[:, 0] = 1  # left finder pattern\n",
    "    dmc_matrix[-1, :] = 1 # bottom finder pattern\n",
    "    # top finder pattern (top even indices)\n",
    "    for i in range(0, 16, 2):\n",
    "        dmc_matrix[0, i] = 1\n",
    "    # right finder pattern (right odd indices)\n",
    "    for i in range(1, 16, 2):\n",
    "        dmc_matrix[i, -1] = 1\n",
    "    if debug:\n",
    "        print(\"DMC matrix post fix\")\n",
    "        display_DMC(dmc_matrix)\n",
    "\n",
    "    # === Decoding DMC ===\n",
    "    decoded_data = decode_DMC(dmc_matrix)\n",
    "    if debug:\n",
    "        print(f\"Decoded data: {decoded_data}\")\n",
    "\n",
    "    return decoded_data\n",
    "\n",
    "img_to_test = \"../data/delete.jpg\"\n",
    "template_to_test = \"../data/delete_template.jpg\"\n",
    "tm_method = cv2.TM_CCOEFF_NORMED\n",
    "tmm_thresh = 0.7\n",
    "nms_thresh = 0.3\n",
    "k_templates = 100\n",
    "N = 1\n",
    "alpha = 4\n",
    "decoded_data = decode_pipeline(img_to_test, template_to_test, tm_method, tmm_thresh, nms_thresh, k_templates, N, alpha, debug=True, rotation=45)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
